{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "# import classifiers\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import mne\n",
    "from mne.preprocessing import EOGRegression\n",
    "from mne.defaults import HEAD_SIZE_DEFAULT\n",
    "from mne.channels._standard_montage_utils import _read_theta_phi_in_degrees\n",
    "\n",
    "# set directories\n",
    "dir                 = '/home/amber/OneDrive/code/nAdaptation_EEG_git/' # to save figures\n",
    "dir_data            = 'data/EEG/raw/'\n",
    "dir_behaviour       = 'data/behaviour/'\n",
    "\n",
    "# extract eeg files\n",
    "eeg_files = sorted(glob.glob(dir_data + '*.bdf'))\n",
    "# print(eeg_files)\n",
    "\n",
    "# extract behaviour files\n",
    "behaviour_files = sorted(glob.glob(dir_behaviour + '*.txt'))\n",
    "# print(behaviour_files)\n",
    "\n",
    "# determine \n",
    "assert len(eeg_files) == len(behaviour_files) # throws error if number of eeg files doesn't match number of behavioural files\n",
    "n_sub = len(eeg_files)\n",
    "\n",
    "for i in range(len(eeg_files)):\n",
    "    assert behaviour_files[i][-9:-4] == eeg_files[i][-9:-4]\n",
    "\n",
    "# exclude subjects\n",
    "exclude = []\n",
    "n_sub = len(eeg_files)\n",
    "\n",
    "print('\\nNumber of subjects: ', n_sub - len(exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# montage - creates visualization of cap when figures are plotted with mne functions\n",
    "fname = dir + 'config/chs.tsv'\n",
    "montage = _read_theta_phi_in_degrees(fname=fname, head_size=HEAD_SIZE_DEFAULT,\n",
    "                                    fid_names=['Nz', 'LPA', 'RPA'],\n",
    "                                    add_fiducials=False)\n",
    "\n",
    "# set reference electrodes\n",
    "reference       = ['EMGL', 'EMGR']\n",
    "eog             = ['EOGL', 'EOGR', 'EOGT', 'EOGB']\n",
    "exc             = ['EXG7', 'EXG8', 'GSR1', 'GSR2', 'Erg1', 'Erg2', 'Resp', 'Plet', 'Temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "tmin                    = -0.1\n",
    "tmax                    = 0.5\n",
    "sample_rate             = 2048\n",
    "down_sample_rate        = 256\n",
    "\n",
    "# band-pass frequencies\n",
    "f_low       = 0.1           # high-pass filter\n",
    "f_high      = 30            # low-pass filter\n",
    "\n",
    "f_notch     = 50            # notch filter\n",
    "\n",
    "# targets\n",
    "targets                 = [3, 6, 8, 9]\n",
    "n_targets               = len(targets)\n",
    "\n",
    "# set timepoints\n",
    "n_timepoints            = math.ceil((abs(tmin) + tmax)/(1/down_sample_rate))\n",
    "t                       = np.arange(n_timepoints)*(1/down_sample_rate)+tmin\n",
    "\n",
    "# reject criteria to exclude certain epochs based on min/max voltages\n",
    "# reject_criteria         = dict(eeg=3.6e-4)\n",
    "# flat_criteria           = dict(eeg=50e-10)\n",
    "reject_criteria         = None\n",
    "flat_criteria           = None\n",
    "\n",
    "# channel info\n",
    "n_channels      = 64\n",
    "\n",
    "global channel_names # (e.g. Oz, Fp1) will be added later in the loop over subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial types\n",
    "trial_type_clean                = 'clean'\n",
    "trial_type_single               = 'single'\n",
    "trial_type_repeated             = 'repeated'\n",
    "\n",
    "# number of repetitions\n",
    "repetitions_clean               = 100 * n_targets\n",
    "repetitions_single              = 8 * n_targets\n",
    "repetitions_repeated            = 8 * n_targets\n",
    "\n",
    "# contrast\n",
    "contrast_clean                  = ['f_contrast']\n",
    "contrast_clean_values           = [1]\n",
    "\n",
    "contrast_single                 = ['l_contrast', 'lm_contrast', 'm_contrast', 'mh_contrast', 'h_contrast']\n",
    "contrast_single_values          = [0.50, 0.60, 0.70, 0.80, 0.90]\n",
    "\n",
    "contrast_repeated               = ['l_contrast', 'lm_contrast', 'm_contrast', 'mh_contrast', 'h_contrast']\n",
    "contrast_repeated_values        = [0.50, 0.60, 0.70, 0.80, 0.90]\n",
    "\n",
    "# adapter\n",
    "adapter_clean                   = ['none']\n",
    "adapter_single                  = ['none']\n",
    "adapter_repeated                = ['same', 'different']\n",
    "\n",
    "# image types for which we are going to extract the trigger numbers\n",
    "img_type_clean                  = ['test']\n",
    "img_type_single                 = ['test']\n",
    "img_type_repeated               = ['test']\n",
    "\n",
    "# concatenate information for the different trial types\n",
    "trial_types                     = [trial_type_clean, trial_type_single, trial_type_repeated]\n",
    "repetitions                     = [repetitions_clean, repetitions_single, repetitions_repeated]\n",
    "contrasts                       = [contrast_clean, contrast_single, contrast_repeated]\n",
    "contrasts_value                 = [contrast_clean_values, contrast_single_values, contrast_repeated_values]\n",
    "adapters                        = [adapter_clean, adapter_single, adapter_repeated]\n",
    "img_types                       = [img_type_clean, img_type_single, img_type_repeated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate dataframes\n",
    "data_clean          = np.zeros((n_sub,      len(contrast_clean),         len(adapter_clean),         repetitions_clean,         n_channels,        n_timepoints))\n",
    "data_single         = np.zeros((n_sub,      len(contrast_single),        len(adapter_single),        repetitions_single,        n_channels,      n_timepoints))\n",
    "data_repeated       = np.zeros((n_sub,      len(contrast_repeated),      len(adapter_repeated),      repetitions_repeated,      n_channels,    n_timepoints))\n",
    "\n",
    "# shape (n_sub x contrast x adapter x channels x timepoints)\n",
    "print('Shape data struct for clean trials: '.ljust(50), data_clean.shape)\n",
    "print('Shape data struct for single trials: '.ljust(50), data_single.shape)\n",
    "print('Shape data struct for repeated trials: '.ljust(50), data_repeated.shape)\n",
    "\n",
    "data                = [data_clean, data_single, data_repeated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define two functions that we use when we loop through the subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triggerNum_extract(file, trial_types, contrasts, adapters):\n",
    "\n",
    "    # initiate lis to store trigger numbers\n",
    "    dic_triggerNums = {}\n",
    "\n",
    "    for iT, trial_type in enumerate(trial_types):\n",
    "\n",
    "            # initiate nested dictionairy\n",
    "            dic_trial_type = {}\n",
    "\n",
    "            for contrast in contrasts[iT]:\n",
    "\n",
    "                # initiate nested dictionairy\n",
    "                dic_contrast = {}\n",
    "\n",
    "                for adapter in adapters[iT]:\n",
    "\n",
    "                    # select rows\n",
    "                    idx = file[(file.trial_type == trial_type) & (file.contrast == contrast) & (file.adapter == adapter) & (file.img_type == 'test')].index\n",
    "                    dic_contrast[adapter] = file.loc[idx, 'trigger_num'].unique()[0]\n",
    "\n",
    "                # append to dictionairies\n",
    "                dic_trial_type[contrast] = dic_contrast\n",
    "            dic_triggerNums[trial_type] = dic_trial_type\n",
    "\n",
    "    return dic_triggerNums\n",
    "\n",
    "def create_arrays(sub_index, data_current_subject, events_triggerNums, triggerNums, trial_types, contrasts, adapters):\n",
    "\n",
    "    for iT, trial_type in enumerate(trial_types):\n",
    "            for iC, contrast in enumerate(contrasts[iT]):\n",
    "                for iA, adapter in enumerate(adapters[iT]):\n",
    "\n",
    "                        # select triggerNum\n",
    "                        current_triggerNum = triggerNums[trial_type][contrast][adapter]\n",
    "\n",
    "                        # find indices\n",
    "                        idx = np.where(np.array(events_triggerNums)==current_triggerNum)[0]\n",
    "\n",
    "                        print(trial_type, ',', contrast, ',', adapter, ',', len(idx))\n",
    "\n",
    "                        # add to dataframe\n",
    "                        data[iT][sub_index, iC, iA, :, :, :] = data_current_subject[idx, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mne.set_log_level('WARNING') # suppresses warnings from MNE (less output)\n",
    "\n",
    "# iterate over subjects and extract data\n",
    "count_sub = 0\n",
    "dropped_epochs = np.zeros(n_sub)\n",
    "for i in range(n_sub):\n",
    "\n",
    "    # import behaviour file\n",
    "    df_behaviour = pd.read_csv(behaviour_files[i])\n",
    "    triggerNums = triggerNum_extract(df_behaviour, trial_types, contrasts, adapters)\n",
    "\n",
    "    # import raw data\n",
    "    raw = mne.io.read_raw_bdf(eeg_files[i], eog=eog, misc=reference, exclude=exc, preload=True)\n",
    "    channel_names = raw.info['ch_names'][:n_channels]\n",
    "\n",
    "    # reference signal to mastoids\n",
    "    raw.set_eeg_reference(reference)\n",
    "\n",
    "    # apply band-pass and notch filter\n",
    "    raw.notch_filter(freqs=(f_notch))\n",
    "    raw.filter(l_freq=f_low, h_freq=f_high)\n",
    "\n",
    "    # set electrode montage\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    # find events\n",
    "    events = mne.find_events(raw)\n",
    "    events = mne.pick_events(events, include=df_behaviour['trigger_num'].unique().tolist().remove(-4))\n",
    "    events_triggerNums = events[:, 2].tolist() # contains triggernumbers in temporal order)\n",
    "    \n",
    "    # create epochs\n",
    "    if down_sample_rate == None:\n",
    "        epochs = mne.Epochs(raw, events, baseline=(tmin, 0), picks=['eeg', 'eog'], reject=reject_criteria, flat=flat_criteria, tmin=tmin, tmax=tmax, preload='True')\n",
    "    else:\n",
    "        epochs = mne.Epochs(raw, events, baseline=(tmin, 0), picks=['eeg', 'eog'], reject=reject_criteria, flat=flat_criteria, tmin=tmin, tmax=tmax, preload='True').resample(down_sample_rate, npad='auto')\n",
    "\n",
    "    # EOG regression + baseline correction\n",
    "    model_plain = EOGRegression(picks='eeg', picks_artifact='eog').fit(epochs)\n",
    "    epochs_clean_plain = model_plain.apply(epochs)\n",
    "    epochs_clean_plain.apply_baseline(baseline=(tmin, 0))\n",
    "\n",
    "    # transform to current source density (CSD)\n",
    "    epochs_clean_plain_csd = mne.preprocessing.compute_current_source_density(epochs_clean_plain)\n",
    "\n",
    "    # store data in dataframe\n",
    "    data_current_subject = epochs_clean_plain_csd.get_data(picks=channel_names)\n",
    "\n",
    "    # create and save arrays\n",
    "    create_arrays(i, data_current_subject, events_triggerNums, triggerNums, trial_types, contrasts, adapters)\n",
    "\n",
    "    # increment count\n",
    "    count_sub+=1\n",
    "\n",
    "# save dataframes\n",
    "np.save(dir + 'data/EEG/data_clean', data[0])\n",
    "np.save(dir + 'data/EEG/data_single', data[1])\n",
    "np.save(dir + 'data/EEG/data_repeated', data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne_eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
