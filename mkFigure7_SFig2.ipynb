{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda env 'eeg, Python 3.8.19'\n",
    "\n",
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys\n",
    "import math\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from statsmodels.stats.multitest import multipletests  \n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import statsmodels\n",
    "\n",
    "# import classifiers\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import mne\n",
    "from mne.preprocessing import EOGRegression\n",
    "from mne.defaults import HEAD_SIZE_DEFAULT\n",
    "from mne.channels._standard_montage_utils import _read_theta_phi_in_degrees\n",
    "\n",
    "# define root\n",
    "# root                = '/home/amber/OneDrive/code/nAdaptation_EEG_git/'\n",
    "root                = '/home/amber/Documents/organize_code/nAdaptation_EEG_git/'\n",
    "\n",
    "# extract eeg files\n",
    "eeg_files = sorted(glob.glob(root + 'data/EEG/raw/*.bdf'))\n",
    "print(eeg_files)\n",
    "\n",
    "# extract behaviour files\n",
    "behaviour_files = sorted(glob.glob(root + 'data/behaviour/raw/*.txt'))\n",
    "print(behaviour_files)\n",
    "\n",
    "# determine \n",
    "assert len(eeg_files) == len(behaviour_files) # throws error if number of eeg files doesn't match number of behavioural files\n",
    "n_sub = len(eeg_files)\n",
    "\n",
    "for i in range(len(eeg_files)):\n",
    "    assert behaviour_files[i][-9:-4] == eeg_files[i][-9:-4]\n",
    "\n",
    "# exclude subjects\n",
    "exclude = []\n",
    "n_sub = len(eeg_files)\n",
    "\n",
    "print('\\nNumber of subjects: ', n_sub - len(exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# montage - creates visualization of cap when figures are plotted with mne functions\n",
    "fname = root + 'config/chs.tsv'\n",
    "montage = _read_theta_phi_in_degrees(fname=fname, head_size=HEAD_SIZE_DEFAULT,\n",
    "                                    fid_names=['Nz', 'LPA', 'RPA'],\n",
    "                                    add_fiducials=False)\n",
    "\n",
    "# set reference electrodes\n",
    "reference       = ['EMGL', 'EMGR']\n",
    "eog             = ['EOGL', 'EOGR', 'EOGT', 'EOGB']\n",
    "exc             = ['EXG7', 'EXG8', 'GSR1', 'GSR2', 'Erg1', 'Erg2', 'Resp', 'Plet', 'Temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "tmin                = -0.1\n",
    "tmax                = 1\n",
    "sample_rate         = 2048\n",
    "down_sample_rate    = 256\n",
    "\n",
    "# band-pass frequencies\n",
    "f_low       = 0.1           # high-pass filter\n",
    "f_high      = 30            # low-pass filter\n",
    "\n",
    "f_notch     = 50            # notch filter\n",
    "\n",
    "# targets\n",
    "targets                 = [3, 6, 8, 9]\n",
    "n_targets               = len(targets)\n",
    "\n",
    "# bootstrap\n",
    "CI                  = 95\n",
    "CI_low              = 50 - (0.5*CI)\n",
    "CI_high             = 50 + (0.5*CI)\n",
    "B_repetitions       = 1000\n",
    "\n",
    "# set timepoints\n",
    "if down_sample_rate == 64:\n",
    "    n_timepoints            = math.floor((abs(tmin) + tmax)/(1/down_sample_rate))\n",
    "else:\n",
    "    n_timepoints            = math.ceil((abs(tmin) + tmax)/(1/down_sample_rate))\n",
    "t                       = np.arange(n_timepoints)*(1/down_sample_rate)+tmin\n",
    "print(len(t))\n",
    "\n",
    "# channel info\n",
    "n_channels      = 64\n",
    "\n",
    "global channel_names # (e.g. Oz, Fp1) will be added later in the loop over subjects\n",
    "\n",
    "# number of repetitions\n",
    "n_repeats_clean                 = 100\n",
    "n_repeats_noisy                 = 8\n",
    "\n",
    "# initiate dataframe\n",
    "adapters                    = ['none', 'same', 'different']\n",
    "adapters_color              = ['gray', 'dodgerblue', np.array([212, 170, 0])/255]\n",
    "\n",
    "contrasts                   = ['l_contrast', 'lm_contrast', 'm_contrast', 'mh_contrast', 'h_contrast']\n",
    "cmap                        = plt.cm.get_cmap('cool')\n",
    "contrasts_color             = cmap(np.linspace(0, 1, len(contrasts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mne.set_log_level('WARNING') # suppresses warnings from MNE (less output)\n",
    "\n",
    "# # initiate dataframes for decoding analysis\n",
    "# data_clean      = np.zeros((n_sub, n_targets, n_repeats_clean, n_channels, n_timepoints))\n",
    "# data_noisy      = np.zeros((n_sub, len(adapters), len(contrasts), n_targets, n_repeats_noisy, n_channels, n_timepoints))\n",
    "\n",
    "# # retrieve data\n",
    "# for iS in range(n_sub):\n",
    "# # for iS in range(1):\n",
    "\n",
    "#     print('Subject ', iS+1, '...')\n",
    "\n",
    "#     # import behaviour file\n",
    "#     df_behaviour_current = pd.read_csv(behaviour_files[iS])\n",
    "\n",
    "#     # import raw data\n",
    "#     raw = mne.io.read_raw_bdf(eeg_files[iS], eog=eog, misc=reference, exclude=exc, preload=True)\n",
    "#     channel_names = raw.info['ch_names'][:n_channels]\n",
    "\n",
    "#     # reference signal to mastoids\n",
    "#     raw.set_eeg_reference(reference)\n",
    "\n",
    "#     # apply band-pass and notch filter\n",
    "#     raw.notch_filter(freqs=(f_notch))\n",
    "#     raw.filter(l_freq=f_low, h_freq=f_high)\n",
    "\n",
    "#     # set electrode montage\n",
    "#     raw.set_montage(montage)\n",
    "\n",
    "#     # find all events\n",
    "#     events = mne.find_events(raw)\n",
    "\n",
    "#     ######################### CLEAN\n",
    "#     ##############################################################\n",
    "#     ##############################################################\n",
    "\n",
    "#     # sort trials in the order they were presented\n",
    "#     df_behaviour_sorted = df_behaviour_current.sort_values('trial_order')\n",
    "\n",
    "#     # select data rows\n",
    "#     idx = df_behaviour_sorted[(df_behaviour_sorted.trial_type == 'clean')].index\n",
    "#     df_behaviour_sorted = df_behaviour_sorted.loc[idx, :]\n",
    "#     df_behaviour_sorted.reset_index(drop=True, inplace=True)\n",
    "#     trigger_num = df_behaviour_sorted.loc[:, 'trigger_num'].unique().tolist()\n",
    "#     # print(df_behaviour_sorted)\n",
    "\n",
    "#     # select noisy events\n",
    "#     events_noisy = mne.pick_events(events, include=trigger_num)\n",
    "\n",
    "#     # create epochs\n",
    "#     if down_sample_rate == None:\n",
    "#         epochs = mne.Epochs(raw, events_noisy, baseline=(tmin, 0), picks=['eeg', 'eog'], tmin=tmin, tmax=tmax, preload='True')\n",
    "#     else:\n",
    "#         epochs = mne.Epochs(raw, events_noisy, baseline=(tmin, 0), picks=['eeg', 'eog'], tmin=tmin, tmax=tmax, preload='True').resample(down_sample_rate, npad='auto')\n",
    "\n",
    "#     # transform to current source density (CSD) - noisy\n",
    "#     epochs_clean_plain_csd = mne.preprocessing.compute_current_source_density(epochs)\n",
    "\n",
    "#     for iT, target in enumerate(targets):\n",
    "\n",
    "#         # extract noisy images\n",
    "#         index = df_behaviour_sorted[(df_behaviour_sorted.target_class == target)].index\n",
    "#         # print(len(index))\n",
    "\n",
    "#         # rerieve data (events x channels x timepoints)\n",
    "#         data_current = epochs_clean_plain_csd.get_data(picks=channel_names)\n",
    "#         data_clean[iS, iT, :, :, :] = data_current[index, :, :]\n",
    "\n",
    "#     ######################### NOISY\n",
    "#     ##############################################################\n",
    "#     ##############################################################\n",
    "\n",
    "#     # sort trials in the order they were presented\n",
    "#     df_behaviour_sorted = df_behaviour_current.sort_values('trial_order')\n",
    "\n",
    "#     # select data rows\n",
    "#     idx = df_behaviour_sorted[((df_behaviour_sorted.trial_type == 'repeated') | (df_behaviour_sorted.trial_type == 'single')) & (df_behaviour_sorted.img_type == 'test')].index\n",
    "#     df_behaviour_sorted = df_behaviour_sorted.loc[idx, :]\n",
    "#     df_behaviour_sorted.reset_index(drop=True, inplace=True)\n",
    "#     trigger_num = df_behaviour_sorted.loc[:, 'trigger_num'].unique().tolist()\n",
    "#     # print(df_behaviour_sorted)\n",
    "\n",
    "#     # select noisy events\n",
    "#     events_noisy = mne.pick_events(events, include=trigger_num)\n",
    "\n",
    "#     # create epochs\n",
    "#     if down_sample_rate == None:\n",
    "#         epochs = mne.Epochs(raw, events_noisy, baseline=(tmin, 0), picks=['eeg', 'eog'], tmin=tmin, tmax=tmax, preload='True')\n",
    "#     else:\n",
    "#         epochs = mne.Epochs(raw, events_noisy, baseline=(tmin, 0), picks=['eeg', 'eog'], tmin=tmin, tmax=tmax, preload='True').resample(down_sample_rate, npad='auto')\n",
    "\n",
    "#     # transform to current source density (CSD) - noisy\n",
    "#     epochs_clean_plain_csd = mne.preprocessing.compute_current_source_density(epochs)\n",
    "\n",
    "#     for iA, adapter in enumerate(adapters):\n",
    "#         for iC, contrast in enumerate(contrasts):\n",
    "#             for iT, target in enumerate(targets):\n",
    "\n",
    "#                 # extract noisy images\n",
    "#                 if adapter == 'none':\n",
    "#                     index = df_behaviour_sorted[(df_behaviour_sorted.trial_type == 'single') & (df_behaviour_sorted.contrast == contrast) & (df_behaviour_sorted.target_class == target)].index\n",
    "#                 else:\n",
    "#                     index = df_behaviour_sorted[(df_behaviour_sorted.trial_type == 'repeated') & (df_behaviour_sorted.adapter == adapter) & (df_behaviour_sorted.contrast == contrast) & (df_behaviour_sorted.target_class == target)].index\n",
    "#                 # print(len(index))\n",
    "        \n",
    "#                 # rerieve data (events x channels x timepoints)\n",
    "#                 data_current = epochs_clean_plain_csd.get_data(picks=channel_names)\n",
    "#                 data_noisy[iS, iA, iC, iT, :, :, :] = data_current[index, :, :]\n",
    "\n",
    "# # clean images\n",
    "# np.save(root + 'data/EEG/decoding_clean_data_256Hz', data_clean)\n",
    "\n",
    "# # noisy images\n",
    "# np.save(root + 'data/EEG/decoding_noisy_data_256Hz', data_noisy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean images\n",
    "data_accu_clean = np.load(root + 'data/EEG/decoding_clean_data_256Hz.npy')\n",
    "\n",
    "# noisy images\n",
    "data_accu_noisy = np.load(root + 'data/EEG/decoding_noisy_data_256Hz.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode clean images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of splits for k-fold cross validation\n",
    "n_split     = 10\n",
    "\n",
    "# initiate dataframe\n",
    "decoding_accu_clean = np.ones((n_sub, n_timepoints)) * 0.25\n",
    "\n",
    "# sliding window\n",
    "window_clean      = 10\n",
    "print('Time window: ', np.round(2*window_clean*(1/down_sample_rate)*1000, 2), 'ms')\n",
    "\n",
    "# avarege over n trials\n",
    "clean_trial_avg       = 1\n",
    "\n",
    "# average every n trials\n",
    "data_clean_avg      = np.zeros((n_sub, n_targets, int(n_repeats_clean/clean_trial_avg), n_channels, n_timepoints))\n",
    "for iR in range(int(n_repeats_clean/clean_trial_avg)):\n",
    "    start = iR*clean_trial_avg\n",
    "    data_clean_avg[:, :, iR, :, :] = data_clean[:, :, start:start+clean_trial_avg, :, :].mean(2)\n",
    "\n",
    "# create labels\n",
    "df = pd.DataFrame(columns=['target', 'repeats'])\n",
    "for iT, target in enumerate(targets):\n",
    "    for iR in range(int(n_repeats_clean/clean_trial_avg)):\n",
    "        df.loc[len(df), :] = [target, int(n_repeats_clean/clean_trial_avg)]\n",
    "print(len(df))\n",
    "\n",
    "for iS in range(n_sub):\n",
    "# for iS in range(5):\n",
    "\n",
    "    print('Current subject: ', iS+1)\n",
    "\n",
    "    for tmp in range(window_clean, n_timepoints):\n",
    "\n",
    "        # select data\n",
    "        if window_clean == 0:\n",
    "            current_data = data_clean_avg[iS, :, :, :, tmp]\n",
    "        else:\n",
    "            current_data = data_clean_avg[iS, :, :, :, tmp-window_clean:tmp+window_clean].mean(3)\n",
    "        current_data = current_data.reshape(current_data.shape[0]*current_data.shape[1], current_data.shape[2])\n",
    "\n",
    "        # cross-validation\n",
    "        kf = KFold(n_splits=n_split, shuffle=True)\n",
    "\n",
    "        # store accuracies for current split\n",
    "        accu_current_split = list()\n",
    "        for k, (train_index, test_index) in enumerate(kf.split(current_data, df.loc[:, 'target'].tolist())):\n",
    "\n",
    "            # initiate classifier\n",
    "            clf = clf = svm.SVC()\n",
    "\n",
    "            # fit\n",
    "            X_train     = current_data[train_index, :]\n",
    "            X_test      = current_data[test_index, :]\n",
    "\n",
    "            # train classifier\n",
    "            clf.fit(X_train, df.loc[train_index, 'target'].tolist())\n",
    "\n",
    "            # predict\n",
    "            pred = clf.predict(X_test)\n",
    "\n",
    "            # save accuracy\n",
    "            accu_current_split.append((pred == df.loc[test_index, 'target'].tolist()).sum()/len(df.loc[test_index, 'target'].tolist()))\n",
    "\n",
    "        # save accuracy     \n",
    "        decoding_accu_clean[iS, tmp] = np.mean(accu_current_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store p-values\n",
    "p_values_adjust_clean = np.ones(n_timepoints)\n",
    "\n",
    "# testing\n",
    "for tmp in range(window_clean, n_timepoints):\n",
    "\n",
    "    # parametric\n",
    "    results = stats.ttest_1samp(decoding_accu_clean[:, tmp], 0.25)\n",
    "    p_values_adjust_clean[tmp] = results[1]\n",
    "\n",
    "# MC correction\n",
    "p_values_adjust_sign_clean = multipletests(p_values_adjust_clean, method='sidak')[1]\n",
    "# print(p_values_adjust_sign_clean)\n",
    "p_values_adjust_sign_clean = np.argwhere(p_values_adjust_sign_clean < 0.05).flatten()\n",
    "print(len(p_values_adjust_sign_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initiate figure\n",
    "# fig = plt.figure()\n",
    "# ax = plt.gca()\n",
    "\n",
    "# # plot decoding accuracies\n",
    "# data_mean = np.mean(decoding_accu_clean[:, :], 0)\n",
    "# data_std = np.std(decoding_accu_clean[:, :], 0)/math.sqrt(n_sub)\n",
    "\n",
    "# # plot data\n",
    "# # ax.plot(t, decoding_accu_clean.T, color='dodgerblue', lw=0.5)\n",
    "# ax.plot(t, data_mean)\n",
    "# ax.fill_between(t, data_mean - data_std, data_mean + data_std, alpha=0.2)\n",
    "\n",
    "# # adjust axes\n",
    "# ax.axhline(1/len(targets), linestyle='dotted', color='grey')\n",
    "# ax.axvline(0, lw=0.5, color='grey', zorder=-10)\n",
    "# ax.axhline(0, lw=0.5, color='grey', zorder=-10)\n",
    "# ax.set_ylim(0.2, 0.35)\n",
    "# ax.set_xlabel('Time (s)')\n",
    "# ax.set_ylabel('Decoding accuracy')\n",
    "# ax.legend(frameon=False)\n",
    "\n",
    "# # plot stats\n",
    "# ax.scatter(t[p_values_adjusted_sign_clean], np.ones(len(p_values_adjusted_sign_clean))*0.22, s=10, color='grey')\n",
    "\n",
    "# plt.title('clean trials (n = ' + str(n_sub) + ')')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(dir + 'visualizations/decoding/decoding_performance', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode noisy images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliding window\n",
    "window_noisy      = 10\n",
    "print('Time window: ', np.round(2*window_noisy*(1/down_sample_rate)*1000, 2), 'ms')\n",
    "\n",
    "# intiate dataframe to store decoding accuracies\n",
    "decoding_accu_noisy       = np.ones((n_sub, len(adapters), len(contrasts), n_timepoints)) * 0.25\n",
    "\n",
    "# initiate dataframe\n",
    "adapters                    = ['none', 'same', 'different']\n",
    "contrasts                   = ['l_contrast', 'lm_contrast', 'm_contrast', 'mh_contrast', 'h_contrast']\n",
    "\n",
    "# avarege over n trials\n",
    "noisy_trial_avg       = 1\n",
    "print(n_repeats_noisy/noisy_trial_avg)\n",
    "\n",
    "# average every n trials\n",
    "data_noise_avg      = np.zeros((n_sub, len(adapters), len(contrasts), n_targets, int(n_repeats_noisy/noisy_trial_avg), n_channels, n_timepoints))\n",
    "for iR in range(int(n_repeats_noisy/noisy_trial_avg)):\n",
    "    start = iR*noisy_trial_avg\n",
    "    data_noise_avg[:, :, :, :, iR, :, :] = data_noisy[:, :, :, :, start:start+noisy_trial_avg, :, :].mean(4)\n",
    "\n",
    "# initiate dataframe\n",
    "df = pd.DataFrame(columns=['adapter', 'contrast', 'target', 'repeats'])\n",
    "\n",
    "# add data\n",
    "for iA, adapter in enumerate(adapters):\n",
    "    for iC, contrast in enumerate(contrasts):\n",
    "        for iT, target in enumerate(targets):\n",
    "            for iR in range(int(n_repeats_noisy/noisy_trial_avg)):\n",
    "                df.loc[len(df), :] = [adapter, contrast, target, iR+1]\n",
    "print(len(df))\n",
    "\n",
    "for iS in range(n_sub):\n",
    "# for iS in range(1):\n",
    "\n",
    "    # print progress\n",
    "    print('Current subject: ', iS+1)\n",
    "\n",
    "    for tmp in range(window_noisy, n_timepoints):\n",
    "\n",
    "        # select data\n",
    "        if window_noisy == 0:\n",
    "            current_data = data_noise_avg[iS, :, :, :, :, :, tmp]\n",
    "        else:\n",
    "            current_data = data_noise_avg[iS, :, :, :, :, :, tmp-window_noisy:tmp+window_noisy].mean(5)\n",
    "        current_data = current_data.reshape(current_data.shape[0]*current_data.shape[1]*current_data.shape[2]*current_data.shape[3], current_data.shape[4])\n",
    "        # print(current_data.shape)\n",
    "\n",
    "        for iA, adapter in enumerate(adapters):\n",
    "            for iC, contrast in enumerate(contrasts):\n",
    "\n",
    "                # initiate classifier\n",
    "                clf = clf = svm.SVC()\n",
    "\n",
    "                # select train and test indices\n",
    "                # test_index = df[(df.adapter == adapter) & (df.contrast == contrast)].index \n",
    "                test_index = df[(df.adapter == adapter) & (df.contrast == contrast)].index                \n",
    "                train_index = [num for num in np.arange(len(df)) if num not in test_index]\n",
    "                            \n",
    "                # select data\n",
    "                X_train = current_data[train_index, :]\n",
    "                X_test = current_data[test_index, :]\n",
    "                \n",
    "                # fit classifier\n",
    "                clf.fit(X_train, df.loc[train_index, 'target'].tolist())\n",
    "\n",
    "                # predict\n",
    "                pred = clf.predict(X_test)\n",
    "\n",
    "                # # save accuracy\n",
    "                decoding_accu_noisy[iS, iA, iC, tmp] = (pred == df.loc[test_index, 'target']).sum()/len(df.loc[test_index, 'target'])\n",
    "\n",
    "\n",
    "# noisy images\n",
    "np.save(root + 'data/EEG/decoding_noisy_data_256Hz', data_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store p-values\n",
    "p_values_adjust_noisy = np.ones(n_timepoints)\n",
    "\n",
    "# testing\n",
    "for tmp in range(window_noisy, n_timepoints):\n",
    "\n",
    "    # parametric\n",
    "    results = stats.ttest_1samp(decoding_accu_noisy[:, :, :, tmp].mean(1).mean(1), 0.25)\n",
    "    p_values_adjust_noisy[tmp] = results[1]\n",
    "\n",
    "# MC correction\n",
    "p_values_adjust_sign_noisy = multipletests(p_values_adjust_noisy, method='sidak')[1]\n",
    "p_values_adjust_sign_noisy = np.argwhere(p_values_adjust_sign_noisy < 0.05).flatten()\n",
    "print(len(p_values_adjust_sign_noisy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # initiate figure\n",
    "# fig = plt.figure()\n",
    "# ax = plt.gca()\n",
    "\n",
    "# # select data\n",
    "# data_current = decoding_accu_noisy[:, :, :, :].mean(1).mean(1)\n",
    "\n",
    "# # plot decoding accuracies\n",
    "# data_mean = np.mean(data_current, 0)\n",
    "# data_std = np.std(data_current, 0)/math.sqrt(n_sub)\n",
    "\n",
    "# # plot data\n",
    "# ax.plot(t, data_mean)\n",
    "# ax.fill_between(t, data_mean - data_std, data_mean + data_std, alpha=0.2)\n",
    "\n",
    "# # plot stats\n",
    "# ax.scatter(t[p_values_adjust_sign_noisy], np.ones(len(p_values_adjust_sign_noisy))*0.22, s=10, color='grey')\n",
    "\n",
    "# # adjust axes\n",
    "# ax.axhline(1/len(targets), linestyle='dotted', color='grey', label='Chance level')\n",
    "# ax.axvline(0, lw=0.5, color='grey', zorder=-10)\n",
    "# ax.axhline(0, lw=0.5, color='grey', zorder=-10)\n",
    "# ax.set_ylim(0.2, 0.35)\n",
    "# ax.set_xlabel('Time (s)')\n",
    "# ax.set_ylabel('Decoding accuracy')\n",
    "# ax.legend(frameon=False)\n",
    "\n",
    "# plt.suptitle('clean trials (n = ' + str(n_sub) + ')')\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(dir + 'visualizations/decoding/decoding_performance_adapter', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import tukey_hsd\n",
    "\n",
    "t_start     = np.argwhere(t > 0)[0][0]\n",
    "t_end       = np.argwhere(t > 0.65)[0][0]\n",
    "\n",
    "# initiate figure\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3), width_ratios=[2, 1])\n",
    "\n",
    "# settings for plotting\n",
    "sns.despine(offset=10)\n",
    "\n",
    "fontsize_title          = 18\n",
    "fontsize_legend         = 12\n",
    "fontsize_label          = 14\n",
    "fontsize_tick           = 12\n",
    "\n",
    "sigma   = 0.5\n",
    "spread  = 0.01\n",
    "\n",
    "cmap                = plt.cm.get_cmap('Blues')\n",
    "color_same          = cmap(np.linspace(0.3, 1, 4))\n",
    "\n",
    "color_diff          = plt.cm.get_cmap('tab20b')\n",
    "color_diff          = color_diff.colors[9:11]\n",
    "# cmap                = plt.cm.get_cmap('YlOrBr')\n",
    "# color_diff          = cmap(np.linspace(0.3, 1, 4))\n",
    "\n",
    "adapters_color  = ['silver', 'dodgerblue', 'goldenrod']\n",
    "\n",
    "lw  = 2\n",
    "s   = 2\n",
    "\n",
    "######################## FULL contrast TIMECOURSES\n",
    "color = 'lightslategray'\n",
    "\n",
    "# select data\n",
    "data_current = decoding_accu_clean\n",
    "\n",
    "print('Mean decoding accuracy - clean: ', np.mean(data_current[:, t_start:t_end]))\n",
    "print('STD decoding accuracy - clean: ', np.std(data_current[:, t_start:t_end])/math.sqrt(n_sub))\n",
    "\n",
    "# plot decoding accuracies\n",
    "data_mean = gaussian_filter1d(np.mean(data_current, 0), sigma)\n",
    "data_std = np.std(data_current, 0)/math.sqrt(n_sub)\n",
    "\n",
    "# plot data\n",
    "axs[0].plot(t, data_mean, color=color, label='clean', lw=lw)\n",
    "axs[0].fill_between(t, data_mean - data_std, data_mean + data_std, color=color, alpha=0.2)\n",
    "\n",
    "# plot stats\n",
    "axs[0].scatter(t[p_values_adjust_sign_clean], np.ones(len(p_values_adjust_sign_clean))*0.2, s=1, color=color)#, transform=ax.transAxes)\n",
    "print('Clean: ', len(t[p_values_adjust_sign_clean]), ' significant timepoints')\n",
    "\n",
    "# save average accuracy\n",
    "avg_dacc = np.zeros((n_sub, len(adapters)+1))\n",
    "\n",
    "######################## FULL contrast AVG\n",
    "color = 'lightslategray'\n",
    "\n",
    "# select data\n",
    "avg_dacc[:, 0] = decoding_accu_clean[:, t_start:t_end].mean(1)\n",
    "\n",
    "# plot decoding accuracies\n",
    "data_mean = np.mean(avg_dacc[:, 0])\n",
    "data_std = np.std(avg_dacc[:, 0])/math.sqrt(n_sub)\n",
    "\n",
    "# plot data\n",
    "axs[1].scatter(-1, data_mean, color=color, edgecolor='white', s=50)\n",
    "axs[1].plot([-1, -1], [data_mean - data_std, data_mean + data_std], color=color, alpha=0.2)\n",
    "\n",
    "# plot individual subjects\n",
    "sns.stripplot(x=np.ones(n_sub)*-1, y=avg_dacc[:, 0], jitter=True, ax=axs[1], color=color, size=4, alpha=0.5, native_scale=True, legend=False, zorder=-10)\n",
    "\n",
    "# visualize\n",
    "for iA, adapter in enumerate(adapters):\n",
    "\n",
    "    if adapter == 'same':\n",
    "        pos = 1\n",
    "    elif adapter == 'different':\n",
    "        pos = 2\n",
    "    elif adapter == 'none':\n",
    "        pos = 0\n",
    "\n",
    "    ############################################ PLOT TIMECOURSES\n",
    "\n",
    "    # select data\n",
    "    data_current = gaussian_filter1d(decoding_accu_noisy[:, iA, :, :].mean(1), sigma)\n",
    "\n",
    "    # plot decoding accuracies\n",
    "    data_mean = gaussian_filter1d(np.mean(data_current, 0), 1)\n",
    "    data_std = gaussian_filter1d(np.std(data_current, 0)/math.sqrt(n_sub), 1)\n",
    "\n",
    "    # plot data\n",
    "    axs[0].plot(t, data_mean, color=adapters_color[iA], label=adapter, lw=lw)\n",
    "    axs[0].fill_between(t, data_mean - data_std, data_mean + data_std, color=adapters_color[iA], alpha=0.2)\n",
    "\n",
    "    # store p-values\n",
    "    p_values_adjust_noisy = np.ones(n_timepoints)\n",
    "\n",
    "    # testing\n",
    "    for tmp in range(window_noisy, n_timepoints):\n",
    "\n",
    "        # parametric\n",
    "        results = stats.ttest_1samp(data_current[:, tmp], 0.25)\n",
    "        p_values_adjust_noisy[tmp] = results[1]\n",
    "\n",
    "    # FDR correction\n",
    "    p_values_adjust_sign_noisy = multipletests(p_values_adjust_noisy, method='fdr_bh')\n",
    "    p_values_adjust_sign_noisy = np.argwhere(p_values_adjust_sign_noisy[1] < 0.05).flatten()\n",
    "\n",
    "    axs[0].scatter(t[p_values_adjust_sign_noisy], np.ones(len(p_values_adjust_sign_noisy))*0.2+spread-spread*(iA+1), s=1, color=adapters_color[iA])\n",
    "\n",
    "    print(adapter, ': ', len(t[p_values_adjust_sign_noisy]), ' significant timepoints')\n",
    "\n",
    "    ############################################ PLOT AVG\n",
    "\n",
    "    # select data\n",
    "    avg_dacc[:, iA+1] = decoding_accu_noisy[:, iA, :, t_start:t_end].mean(2).mean(1)\n",
    "\n",
    "    # plot decoding accuracies\n",
    "    data_mean = np.mean(avg_dacc[:, iA+1])\n",
    "    data_std = np.std(avg_dacc[:, iA+1])/math.sqrt(n_sub)\n",
    "\n",
    "    # plot data\n",
    "    axs[1].scatter(pos, data_mean, color=adapters_color[iA], edgecolor='white', s=50, label=adapter)\n",
    "    axs[1].plot([pos, pos], [data_mean - data_std, data_mean + data_std], color=adapters_color[iA], alpha=0.2)\n",
    "\n",
    "    # plot individual subjects\n",
    "    sns.stripplot(x=np.ones(n_sub)*pos, y=avg_dacc[:, iA+1], jitter=True, ax=axs[1], color=adapters_color[iA], size=4, alpha=0.5, native_scale=True, legend=False, zorder=-10)\n",
    "\n",
    "# adjust axes\n",
    "axs[0].tick_params(axis='both', labelsize=fontsize_tick)\n",
    "axs[0].spines['top'].set_visible(False)\n",
    "axs[0].spines['right'].set_visible(False)\n",
    "axs[0].axhline(1/len(targets), linestyle='dotted', color='black', lw=3, label='Chance level')\n",
    "axs[0].axvline(0, lw=0.5, color='grey', zorder=-10)\n",
    "axs[0].axhline(0, lw=0.5, color='grey', zorder=-10)\n",
    "axs[0].set_ylim(0.15, 0.35)\n",
    "\n",
    "axs[1].tick_params(axis='both', labelsize=fontsize_tick)\n",
    "axs[1].spines['top'].set_visible(False)\n",
    "axs[1].spines['right'].set_visible(False)\n",
    "axs[1].set_xticks(np.arange(len(adapters)+1)-1)\n",
    "axs[1].set_xticklabels([' ', ' ', ' ', ' '], fontsize=fontsize_label, rotation=45, ha=\"right\")\n",
    "axs[1].axhline(0.25, lw=1, linestyle='dashed', color='black', zorder=-10)\n",
    "axs[1].set_ylim(0.20, 0.35)\n",
    "\n",
    "# one-way anova\n",
    "results = f_oneway(avg_dacc[:, 0], avg_dacc[:, 1], avg_dacc[:, 2], avg_dacc[:, 3])\n",
    "print(results)\n",
    "results = tukey_hsd(avg_dacc[:, 0], avg_dacc[:, 1], avg_dacc[:, 2], avg_dacc[:, 3])\n",
    "print(results)\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "        # parametric\n",
    "        results = stats.ttest_1samp(avg_dacc[:, i], 0.25)\n",
    "        print(results)\n",
    "\n",
    "# plt.suptitle('clean trials (n = ' + str(n_sub) + ')')\n",
    "plt.tight_layout()\n",
    "plt.savefig(root + 'visualization/Fig7AB', dpi=300)\n",
    "plt.savefig(root + 'visualization/Fig7AB.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliding window\n",
    "window_noisy      = 10\n",
    "print('Time window: ', np.round(2*window_noisy*(1/down_sample_rate)*1000, 2), 'ms')\n",
    "\n",
    "# intiate dataframe to store decoding accuracies\n",
    "decoding_accu_noisy_contrast       = np.ones((n_sub, len(contrasts), n_timepoints)) * 0.25\n",
    "\n",
    "# initiate dataframe\n",
    "adapters                    = ['none', 'same', 'different']\n",
    "contrasts                   = ['l_contrast', 'lm_contrast', 'm_contrast', 'mh_contrast', 'h_contrast']\n",
    "\n",
    "# avarege over n trials\n",
    "noisy_trial_avg       = 1\n",
    "print(n_repeats_noisy/noisy_trial_avg)\n",
    "\n",
    "# average every n trials\n",
    "data_noise_avg      = np.zeros((n_sub, len(adapters), len(contrasts), n_targets, int(n_repeats_noisy/noisy_trial_avg), n_channels, n_timepoints))\n",
    "for iR in range(int(n_repeats_noisy/noisy_trial_avg)):\n",
    "    start = iR*noisy_trial_avg\n",
    "    data_noise_avg[:, :, :, :, iR, :, :] = data_noisy[:, :, :, :, start:start+noisy_trial_avg, :, :].mean(4)\n",
    "\n",
    "# initiate dataframe\n",
    "df = pd.DataFrame(columns=['adapter', 'contrast', 'target', 'repeats'])\n",
    "\n",
    "# add data\n",
    "for iA, adapter in enumerate(adapters):\n",
    "    for iC, contrast in enumerate(contrasts):\n",
    "        for iT, target in enumerate(targets):\n",
    "            for iR in range(int(n_repeats_noisy/noisy_trial_avg)):\n",
    "                df.loc[len(df), :] = [adapter, contrast, target, iR+1]\n",
    "print(len(df))\n",
    "\n",
    "for iS in range(n_sub):\n",
    "# for iS in range(1):\n",
    "\n",
    "    # print progress\n",
    "    print('Current subject: ', iS+1)\n",
    "\n",
    "    for tmp in range(window_noisy, n_timepoints):\n",
    "\n",
    "        # select data\n",
    "        if window_noisy == 0:\n",
    "            current_data = data_noise_avg[iS, :, :, :, :, :, tmp]\n",
    "        else:\n",
    "            current_data = data_noise_avg[iS, :, :, :, :, :, tmp-window_noisy:tmp+window_noisy].mean(5)\n",
    "        current_data = current_data.reshape(current_data.shape[0]*current_data.shape[1]*current_data.shape[2]*current_data.shape[3], current_data.shape[4])\n",
    "        # print(current_data.shape)\n",
    "\n",
    "        for iC, contrast in enumerate(contrasts):\n",
    "\n",
    "            # initiate classifier\n",
    "            clf = svm.SVC()\n",
    "\n",
    "            # select train and test indices\n",
    "            test_index = df[(df.contrast == contrast)].index                \n",
    "            train_index = [num for num in np.arange(len(df)) if num not in test_index]\n",
    "                        \n",
    "            # select data\n",
    "            X_train = current_data[train_index, :]\n",
    "            X_test = current_data[test_index, :]\n",
    "            \n",
    "            # fit classifier\n",
    "            clf.fit(X_train, df.loc[train_index, 'target'].tolist())\n",
    "\n",
    "            # predict\n",
    "            pred = clf.predict(X_test)\n",
    "\n",
    "            # # save accuracy\n",
    "            decoding_accu_noisy_contrast[iS, iC, tmp] = (pred == df.loc[test_index, 'target']).sum()/len(df.loc[test_index, 'target'])\n",
    "\n",
    "\n",
    "# noisy images\n",
    "np.save(root + 'data/EEG/decoding_noisy_data_256Hz_contrast', decoding_accu_noisy_contrast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "t_start     = np.argwhere(t > 0)[0][0]\n",
    "t_end       = np.argwhere(t > 0.65)[0][0]\n",
    "\n",
    "# initiate figure\n",
    "fig = plt.figure(figsize=(4, 3))\n",
    "axs = plt.gca()\n",
    "\n",
    "# settings for plotting\n",
    "sns.despine(offset=10)\n",
    "\n",
    "fontsize_title          = 18\n",
    "fontsize_legend         = 12\n",
    "fontsize_label          = 14\n",
    "fontsize_tick           = 12\n",
    "\n",
    "sigma                   = 0.5\n",
    "spread                  = 0.01\n",
    "\n",
    "lw                      = 2\n",
    "s                       = 2\n",
    "\n",
    "# set color\n",
    "cmap                        = plt.cm.get_cmap('cool')\n",
    "color_contrasts             = cmap(np.linspace(0, 1, len(contrasts)))\n",
    "\n",
    "# averages\n",
    "avg_dacc = np.zeros((n_sub, len(contrasts)))\n",
    "\n",
    "# visualize\n",
    "for iC, contrast in enumerate(contrasts):\n",
    "\n",
    "    ############################################ PLOT TIMECOURSES\n",
    "\n",
    "    # select data\n",
    "    avg_dacc[:, iC] = decoding_accu_noisy_contrast[:, iC, t_start:t_end].mean(1)\n",
    "\n",
    "    # plot decoding accuracies\n",
    "    data_mean = np.mean(avg_dacc[:, iC])\n",
    "    data_std = np.std(avg_dacc[:, iC])/math.sqrt(n_sub)\n",
    "\n",
    "    # plot data\n",
    "    axs.scatter(iC, data_mean, color=contrasts_color[iC], edgecolor='white', s=50, label=adapter)\n",
    "    axs.plot([iC, iC], [data_mean - data_std, data_mean + data_std], color=contrasts_color[iC], alpha=0.2)\n",
    "\n",
    "    # plot individual subjects\n",
    "    sns.stripplot(x=np.ones(n_sub)*iC, y=avg_dacc[:, iC], jitter=True, ax=axs, color=contrasts_color[iC], size=4, alpha=0.5, native_scale=True, legend=False, zorder=-10)\n",
    "\n",
    "# one-way anova\n",
    "results = f_oneway(avg_dacc[:, 0], avg_dacc[:, 1], avg_dacc[:, 2], avg_dacc[:, 3], avg_dacc[:, 4])\n",
    "print(results)\n",
    "results = tukey_hsd(avg_dacc[:, 0], avg_dacc[:, 1], avg_dacc[:, 2], avg_dacc[:, 3], avg_dacc[:, 4])\n",
    "print(results)\n",
    "\n",
    "axs.tick_params(axis='y', labelsize=fontsize_tick)\n",
    "axs.spines['top'].set_visible(False)\n",
    "axs.spines['right'].set_visible(False)\n",
    "axs.axhline(1/len(targets), linestyle='dotted', color='black', lw=3, label='Chance level')\n",
    "axs.set_xticklabels(['', '50', '60', '70', '80', '90'], size=fontsize_tick)\n",
    "axs.set_xlabel('Contrast target (%)', size=fontsize_label)\n",
    "axs.set_ylim(0.17, 0.32)\n",
    "\n",
    "# save plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(root + 'visualization/SFig2A', dpi=300)\n",
    "plt.savefig(root + 'visualization/SFig2A.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "t_start     = np.argwhere(t > 0)[0][0]\n",
    "t_end       = np.argwhere(t > 0.65)[0][0]\n",
    "\n",
    "# initiate figure\n",
    "fig, axs = plt.subplots(len(contrasts), 1, figsize=(3.5, 8))\n",
    "\n",
    "# settings for plotting\n",
    "sns.despine(offset=10)\n",
    "\n",
    "fontsize_title          = 18\n",
    "fontsize_legend         = 12\n",
    "fontsize_label          = 14\n",
    "fontsize_tick           = 12\n",
    "\n",
    "sigma                   = 0.5\n",
    "spread                  = 0.01\n",
    "\n",
    "lw                      = 2\n",
    "s                       = 2\n",
    "\n",
    "# set color\n",
    "cmap                        = plt.cm.get_cmap('cool')\n",
    "color_contrasts             = cmap(np.linspace(0, 1, len(contrasts)))\n",
    "\n",
    "# visualize\n",
    "for iC, contrast in enumerate(contrasts):\n",
    "\n",
    "    ############################################ PLOT TIMECOURSES\n",
    "\n",
    "    # select data\n",
    "    data_current = gaussian_filter1d(decoding_accu_noisy_contrast[:, iC, :], sigma)\n",
    "\n",
    "    # plot decoding accuracies\n",
    "    data_mean = gaussian_filter1d(np.mean(data_current, 0), 1)\n",
    "    data_std = gaussian_filter1d(np.std(data_current, 0)/math.sqrt(n_sub), 1)\n",
    "\n",
    "    # plot data\n",
    "    axs[iC].plot(t, data_mean, color=color_contrasts[iC], label=contrast, lw=lw)\n",
    "    axs[iC].fill_between(t, data_mean - data_std, data_mean + data_std, color=color_contrasts[iC], alpha=0.2)\n",
    "\n",
    "    # store p-values\n",
    "    p_values_adjust_noisy = np.ones(n_timepoints)\n",
    "\n",
    "    # testing\n",
    "    for tmp in range(window_noisy, n_timepoints):\n",
    "\n",
    "        # parametric\n",
    "        results = stats.ttest_1samp(data_current[:, tmp], 0.25)\n",
    "        p_values_adjust_noisy[tmp] = results[1]\n",
    "    # print(p_values_adjust_noisy)\n",
    "\n",
    "    # FDR correction\n",
    "    p_values_adjust_sign_noisy = multipletests(p_values_adjust_noisy, method='fdr_bh')\n",
    "    p_values_adjust_sign_noisy = np.argwhere(p_values_adjust_noisy < 0.05).flatten()\n",
    "\n",
    "    axs[iC].scatter(t[p_values_adjust_sign_noisy], np.ones(len(p_values_adjust_sign_noisy))*0.22, s=1, color=contrasts_color[iC])\n",
    "\n",
    "    print(contrast, ': ', len(t[p_values_adjust_sign_noisy]), ' significant timepoints')\n",
    "\n",
    "    # adjust axes\n",
    "    axs[iC].tick_params(axis='both', labelsize=fontsize_tick)\n",
    "    axs[iC].spines['top'].set_visible(False)\n",
    "    axs[iC].spines['right'].set_visible(False)\n",
    "    axs[iC].axhline(1/len(targets), linestyle='dotted', color='black', lw=3, label='Chance level')\n",
    "    axs[iC].set_ylim(0.22, 0.3)\n",
    "    axs[iC].axhline(1/len(targets), linestyle='dotted', color='black', lw=3, label='Chance level')\n",
    "    axs[iC].axvline(0, lw=0.5, color='grey', zorder=-10)\n",
    "    axs[iC].axhline(0, lw=0.5, color='grey', zorder=-10)\n",
    "\n",
    "# plt.suptitle('clean trials (n = ' + str(n_sub) + ')')\n",
    "plt.tight_layout()\n",
    "plt.savefig(root + 'visualization/SFig2B', dpi=300)\n",
    "plt.savefig(root + 'visualization/SFig2B.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate figure\n",
    "fig = plt.figure(figsize=(4, 3))\n",
    "ax = plt.gca()\n",
    "\n",
    "# settings for plotting\n",
    "sns.despine(offset=10)\n",
    "\n",
    "fontsize_title          = 15\n",
    "fontsize_legend         = 10\n",
    "fontsize_label          = 12\n",
    "fontsize_tick           = 10\n",
    "\n",
    "############################################ PLOT TIMECOURSES\n",
    "\n",
    "# select data\n",
    "print(decoding_accu_noisy.shape)\n",
    "data_current_same = decoding_accu_noisy[:, 1, :, :].mean(1)\n",
    "print(data_current_same.shape)\n",
    "data_current_diff = decoding_accu_noisy[:, 2, :, :].mean(1)\n",
    "print(data_current_diff.shape)\n",
    "\n",
    "# compute different\n",
    "diff = data_current_same - data_current_diff\n",
    "\n",
    "# # plot decoding accuracies\n",
    "data_mean = gaussian_filter1d(np.mean(diff, 0), 1)\n",
    "data_std = gaussian_filter1d(np.std(diff, 0)/math.sqrt(n_sub), 1)\n",
    "\n",
    "# plot data\n",
    "ax.plot(t, data_mean, color='black', label=adapter)\n",
    "ax.fill_between(t, data_mean - data_std, data_mean + data_std, color='black', alpha=0.2)\n",
    "\n",
    "# store p-values\n",
    "p_values_adjust_noisy = np.ones(n_timepoints)\n",
    "\n",
    "# testing\n",
    "for tmp in range(window_noisy, n_timepoints):\n",
    "\n",
    "    # parametric\n",
    "    results = stats.ttest_1samp(diff[:, tmp], 0)\n",
    "    p_values_adjust_noisy[tmp] = results[1]\n",
    "\n",
    "\n",
    "ax.axhline(0, lw=0.5, color='black')\n",
    "ax.scatter(t[p_values_adjust_sign_noisy], np.ones(len(p_values_adjust_sign_noisy))*0, s=1, color='red')\n",
    "# print(p_values_adjust_noisy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import f_oneway\n",
    "# from scipy.stats import tukey_hsd\n",
    "\n",
    "# # initiate figure\n",
    "# fig = plt.figure(figsize=(4, 3))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# # settings for plotting\n",
    "# sns.despine(offset=10)\n",
    "\n",
    "# fontsize_title          = 15\n",
    "# fontsize_legend         = 10\n",
    "# fontsize_label          = 12\n",
    "# fontsize_tick           = 10\n",
    "\n",
    "# # create strings for subject\n",
    "# subject_str = []\n",
    "# for i in range(n_sub):\n",
    "#     subject_str.append('sub' + str(i+1))\n",
    "\n",
    "# # initiate dataframe\n",
    "# df_stats = pd.DataFrame()\n",
    "# df_stats['subject'] = np.tile(subject_str, len(adapters)*len(contrasts))\n",
    "# df_stats['contrast'] = np.repeat(contrasts, len(adapters)*(n_sub))\n",
    "# df_stats['adapter'] = np.tile(np.repeat(adapters, n_sub), len(contrasts))\n",
    "# df_stats['dependentVar'] = 0\n",
    "# # print(df_stats)\n",
    "\n",
    "# # time window\n",
    "# t_start     = np.argwhere(t > 0)[0][0]\n",
    "# t_end       = np.argwhere(t > 0.99)[0][0]\n",
    "\n",
    "# # colors\n",
    "# cmap                = plt.cm.get_cmap('Blues')\n",
    "# color_same          = cmap(np.linspace(0.3, 1, 4))\n",
    "\n",
    "# # color_diff          = plt.cm.get_cmap('tab20b')\n",
    "# # color_diff          = color_diff.colors[8:11]\n",
    "# cmap                = plt.cm.get_cmap('YlOrBr')\n",
    "# color_diff          = cmap(np.linspace(0.3, 1, 4))\n",
    "\n",
    "# adapters_color  = ['darkgrey', color_same[1], color_diff[1]]\n",
    "\n",
    "# # adapter typoe\n",
    "# adapters_plot = ['none', 'same', 'different']\n",
    "\n",
    "# # offset adapter wrt x-axis\n",
    "# offset_iC = np.array([0, 4, 8, 12, 16])\n",
    "# offset_iA = [-1, 0, 1]\n",
    "\n",
    "# # visualize\n",
    "# for iA, adapter in enumerate(adapters):\n",
    "\n",
    "#     # ############################################ PLOT CONTRAST\n",
    "\n",
    "#     # select data\n",
    "#     data_current = decoding_accu_noisy[:, iA, :, t_start:t_end].mean(2)\n",
    "\n",
    "#     # plot decoding accuracies\n",
    "#     data_mean = np.mean(data_current, 0)\n",
    "#     data_std = np.std(data_current, 0)/math.sqrt(n_sub)\n",
    "\n",
    "#     # plot data\n",
    "#     # axs[1].bar(offset_iC+offset_iA[iA], data_mean, color=adapters_color[iA], edgecolor='white', label=adapter)\n",
    "#     ax.scatter(offset_iC+offset_iA[iA], data_mean, color=adapters_color[iA], edgecolor='white', label=adapter)\n",
    "\n",
    "#     # plot individual subjects\n",
    "#     for iC, contrast in enumerate(contrasts):\n",
    "\n",
    "#         # visualize\n",
    "#         axs[1].plot([offset_iC[iC]+offset_iA[iA], offset_iC[iC]+offset_iA[iA]], [data_mean[iC] - data_std[iC], data_mean[iC] + data_std[iC]], color=adapters_color[iA])\n",
    "#         sns.stripplot(x=np.ones(n_sub)*offset_iC[iC]+offset_iA[iA], y=data_current[:, iC], jitter=True, ax=ax, color=adapters_color[iA], size=3, alpha=0.5, native_scale=True, legend=False, zorder=-10)\n",
    "\n",
    "#         # add to dataframe\n",
    "#         idx = df_stats[(df_stats.contrast == contrast) & (df_stats.adapter == adapter)].index\n",
    "#         df_stats.loc[idx, 'dependentVar'] = data_current[:, iC]\n",
    "\n",
    "#     # fit regression\n",
    "#     pred = np.zeros((n_sub, len(contrasts)))\n",
    "#     for iS in range(n_sub):\n",
    "#         model = scipy.stats.linregress(np.arange(len(contrasts)), data_current[iS, :])\n",
    "#         pred[iS, :] = model.intercept + model.slope * np.arange(len(contrasts))\n",
    "#     ax.plot(np.array(offset_iC)+offset_iA[iA], np.mean(pred, 0), color=adapters_color[iA], zorder=-10)\n",
    "\n",
    "#     # adjust axes\n",
    "#     ax.tick_params(axis='both', labelsize=fontsize_tick)\n",
    "#     ax.spines['top'].set_visible(False)\n",
    "#     ax.spines['right'].set_visible(False)\n",
    "#     ax.set_xticks(offset_iC)\n",
    "#     ax.set_xticklabels(['50', '60', '70', '80', '90'], fontsize=fontsize_label)\n",
    "#     # ax.set_ylabel('Decoding accuracy', fontsize=fontsize_label)\n",
    "#     # ax.set_xlabel('Contrast (%)', fontsize=fontsize_label)\n",
    "#     # ax.axhline(0.25, linestyle='dotted', color='black', lw=1, zorder=-10)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(root + 'visualization/Fig8B', dpi=300)\n",
    "# plt.savefig(root + 'visualization/Fig8B.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contrast"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
